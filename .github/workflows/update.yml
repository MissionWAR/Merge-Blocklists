name: Merge Blocklists

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */12 * * *"   # Every 12 hours (00:00, 12:00 UTC)

env:
  RAW_OUT: lists/_raw
  MERGED_OUT: lists/merged.txt
  FETCH_CONCURRENCY: 8
  FETCH_RETRIES: 3
  FETCH_TIMEOUT: 30
  PYTHON_VERSION: "3.11"

permissions:
  contents: write

jobs:
  update:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      # ============================================
      # Setup
      # ============================================
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1  # Shallow clone for faster checkout

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --no-cache-dir -r requirements.txt
          echo "✅ Dependencies installed"

      # ============================================
      # Caching
      # ============================================
      - name: Restore blocklist cache
        uses: actions/cache@v4
        with:
          path: .cache
          key: blocklists-cache-${{ hashFiles('sources.txt') }}-${{ github.run_id }}
          restore-keys: |
            blocklists-cache-${{ hashFiles('sources.txt') }}-
            blocklists-cache-

      # ============================================
      # Fetch & Process
      # ============================================
      - name: Fetch blocklist sources
        id: fetch
        run: |
          set -euo pipefail
          echo "🔄 Fetching blocklists from sources..."
          
          python -m scripts.fetch_sources \
            --sources sources.txt \
            --outdir "${{ env.RAW_OUT }}" \
            --cache .cache \
            --concurrency "${{ env.FETCH_CONCURRENCY }}" \
            --retries "${{ env.FETCH_RETRIES }}" \
            --timeout "${{ env.FETCH_TIMEOUT }}"
          
          # Count fetched files
          RAW_COUNT=$(find "${{ env.RAW_OUT }}" -type f -name "*.txt" | wc -l)
          echo "raw_files=$RAW_COUNT" >> $GITHUB_OUTPUT
          echo "✅ Fetched $RAW_COUNT source files"

      - name: Process blocklists through pipeline
        id: pipeline
        run: |
          set -euo pipefail
          echo "⚙️ Processing through pipeline..."
          
          # Run the full pipeline
          python -m scripts.pipeline "${{ env.RAW_OUT }}" "${{ env.MERGED_OUT }}"
          
          # Verify output exists
          if [ ! -f "${{ env.MERGED_OUT }}" ]; then
            echo "❌ ERROR: Merged output file not created"
            exit 1
          fi
          
          echo "✅ Pipeline completed successfully"

      - name: Calculate statistics
        id: stats
        run: |
          set -euo pipefail
          
          # Count total rules (non-comment, non-empty lines)
          TOTAL_RULES=$(grep -cvE '^\s*($|[#!])' "${{ env.MERGED_OUT }}" || echo "0")
          
          # Get file size
          FILE_SIZE=$(du -h "${{ env.MERGED_OUT }}" | cut -f1)
          
          # Count cache entries
          CACHE_FILES=$(find .cache -type f -name "*.txt" 2>/dev/null | wc -l || echo "0")
          
          # Output to step outputs and environment
          echo "total_rules=$TOTAL_RULES" >> $GITHUB_OUTPUT
          echo "file_size=$FILE_SIZE" >> $GITHUB_OUTPUT
          echo "TOTAL_RULES=$TOTAL_RULES" >> $GITHUB_ENV
          
          echo "📊 Statistics:"
          echo "  - Total rules: $TOTAL_RULES"
          echo "  - File size: $FILE_SIZE"
          echo "  - Cached sources: $CACHE_FILES"

      # ============================================
      # Validation
      # ============================================
      - name: Validate output
        run: |
          set -euo pipefail
          
          # Check minimum rule count (prevent empty releases)
          MIN_RULES=1000
          if [ "${{ steps.stats.outputs.total_rules }}" -lt "$MIN_RULES" ]; then
            echo "⚠️ WARNING: Only ${{ steps.stats.outputs.total_rules }} rules (expected >$MIN_RULES)"
            echo "This might indicate a fetch/processing issue"
            exit 1
          fi
          
          echo "✅ Output validated (${{ steps.stats.outputs.total_rules }} rules)"

      # ============================================
      # Release
      # ============================================
      - name: Generate release notes
        id: release_notes
        if: steps.stats.outputs.total_rules != '0'
        run: |
          cat > release_notes.md << EOF
          ## Merged Blocklist
          
          **Updated**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')
          
          ### Statistics
          - **Total Rules**: ${{ steps.stats.outputs.total_rules }}
          - **File Size**: ${{ steps.stats.outputs.file_size }}
          - **Sources Processed**: ${{ steps.fetch.outputs.raw_files }}
          EOF
          
          echo "✅ Release notes generated"

      - name: Create or update release
        if: steps.stats.outputs.total_rules != '0'
        uses: softprops/action-gh-release@v2
        with:
          tag_name: merged-latest
          name: Merged Blocklist (Latest)
          body_path: release_notes.md
          files: ${{ env.MERGED_OUT }}
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # ============================================
      # Cleanup & Summary
      # ============================================
      - name: Cleanup old cache entries
        if: always()
        run: |
          echo "🧹 Cleaning up old cache entries (>7 days)..."
          find .cache -type f -mtime +7 -delete 2>/dev/null || true
          
          # Clean up temporary files
          rm -rf lists/_raw 2>/dev/null || true
          
          echo "✅ Cleanup completed"

      - name: Generate job summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY << EOF
          # 📋 Blocklist Update Summary
          
          ## Status
          - **Workflow**: ${{ job.status }}
          - **Duration**: ${{ steps.stats.conclusion == 'success' && '✅ Success' || '❌ Failed' }}
          
          ## Statistics
          | Metric | Value |
          |--------|-------|
          | Total Rules | ${{ steps.stats.outputs.total_rules || 'N/A' }} |
          | File Size | ${{ steps.stats.outputs.file_size || 'N/A' }} |
          | Sources Fetched | ${{ steps.fetch.outputs.raw_files || 'N/A' }} |
          
          ## Timestamps
          - **Started**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')
          - **Run ID**: ${{ github.run_id }}
          - **Commit**: \`${{ github.sha }}\`
          
          ## Next Update
          Scheduled for: **12 hours from now**
          EOF
          
          echo "✅ Job summary generated"
